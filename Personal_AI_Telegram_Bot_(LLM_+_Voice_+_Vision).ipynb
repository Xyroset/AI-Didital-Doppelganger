{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xyroset/AI-Didital-Doppelganger/blob/main/Personal_AI_Telegram_Bot_(LLM_%2B_Voice_%2B_Vision).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ¤– Personal AI Telegram Bot (LLM + Voice + Vision)**\n",
        "\n",
        "### **!! The bot is designed for a single user!!**\n",
        "Otherwise, Google Colab may freeze or overload.\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Welcome!**\n",
        " This notebook allows you to deploy your own fully customizable AI companion directly in Telegram.\n",
        "\n",
        "It uses a local **LLM(unsloth)** for smart conversations, **XTTS** for natural voice generation, and the **Groq API** to instantly understand your voice messages and photos.\n",
        "\n",
        "### **Before you start:**\n",
        "\n",
        "1. **Models:** Make sure you have uploaded your LLM and TTS models to your Google Drive.\n",
        "\n",
        "2. **Hardware:** This code requires a GPU. Go to the top menu: `Runtime` âž” `Change runtime` type and select T4 GPU.\n",
        "\n",
        "3. **API Keys:** You will need a Telegram Bot Token (from `@BotFather`) and a free [Groq API Key](https://console.groq.com/keys \"Groq\").\n",
        "\n",
        "Just follow the steps below, run the cells one by one, and your AI friend will be online!"
      ],
      "metadata": {
        "id": "yzJLHtlQzFnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Install libraries**\n",
        "\n",
        "This is the first step. Run this block to download and install all the necessary dependencies for the AI models, voice generation (TTS), and the Telegram bot framework.\n",
        "\n",
        "After installation, you will see `Compete!` and the session will **restart**."
      ],
      "metadata": {
        "id": "rWtqaX-GacA_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PfX83rDHxF-",
        "outputId": "3830d022-213e-4e91-be2a-2797f8308e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1/5] Install system libraries..\n",
            "\n",
            "[2/5] Set default state for Unsloth & Bot...\n",
            "   -> Installing Unsloth...\n",
            "   -> Installing Aiogram, Groq and etc\n",
            "\n",
            "[3/5] Create venv for TTS...\n",
            "   -> Create folder venv...\n",
            "\n",
            "[4/5] Install libraries for VENV (Torch, TTS)...\n",
            "   -> Fix version inside venv...\n",
            "\n",
            "[5/5] Confirm patch...\n",
            "   -> Patch is complete.\n",
            "\n",
            "Complete! 724 sec.\n",
            "Restart...\n"
          ]
        }
      ],
      "source": [
        "# @title ### **Install**\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "venv_dir = \"/content/tts_venv\"\n",
        "venv_bin = f\"{venv_dir}/bin\"\n",
        "venv_python = f\"{venv_bin}/python\"\n",
        "venv_pip = f\"{venv_bin}/pip\"\n",
        "\n",
        "print(\"\\n[1/5] Install system libraries..\")\n",
        "subprocess.run(\"sudo apt-get update -qq\", shell=True)\n",
        "subprocess.run(\"sudo apt-get install -y -qq espeak-ng libsndfile1-dev ffmpeg\", shell=True)\n",
        "\n",
        "print(\"\\n[2/5] Set default state for Unsloth & Bot...\")\n",
        "\n",
        "subprocess.run(\"pip uninstall -y TTS coqui-tts transformers tokenizers numpy\", shell=True)\n",
        "\n",
        "print(\"   -> Installing Unsloth...\")\n",
        "subprocess.run(\"pip install 'unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git'\", shell=True)\n",
        "subprocess.run(\"pip install --no-deps 'xformers<0.0.27' 'trl<0.8.0' peft accelerate bitsandbytes\", shell=True)\n",
        "\n",
        "print(\"   -> Installing Aiogram, Groq and etc\")\n",
        "subprocess.run(\"pip install aiogram groq Pillow moviepy lottie cairosvg\", shell=True)\n",
        "\n",
        "print(\"\\n[3/5] Create venv for TTS...\")\n",
        "\n",
        "if not os.path.exists(venv_python):\n",
        "    print(\"   -> Create folder venv...\")\n",
        "    subprocess.run(f\"python3 -m venv {venv_dir}\", shell=True)\n",
        "\n",
        "if not os.path.exists(venv_pip):\n",
        "    subprocess.run(\"curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\", shell=True)\n",
        "    subprocess.run(f\"{venv_python} get-pip.py\", shell=True)\n",
        "\n",
        "print(\"\\n[4/5] Install libraries for VENV (Torch, TTS)...\")\n",
        "\n",
        "def install_in_venv(args):\n",
        "    cmd = f\"{venv_pip} install {args}\"\n",
        "    try:\n",
        "        subprocess.check_call(cmd.split())\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"Erro: {args}\")\n",
        "        raise\n",
        "try:\n",
        "    install_in_venv(\"--upgrade pip\")\n",
        "\n",
        "    install_in_venv(\"torch torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
        "\n",
        "    install_in_venv(\"coqui-tts==0.24.1\")\n",
        "    install_in_venv(\"torchcodec soundfile typing-extensions\")\n",
        "\n",
        "    print(\"   -> Fix version inside venv...\")\n",
        "    install_in_venv(\"numpy==1.26.4 transformers==4.45.2 tokenizers==0.20.3\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error Venv: {e}\")\n",
        "\n",
        "print(\"\\n[5/5] Confirm patch...\")\n",
        "\n",
        "target_file = f\"{venv_dir}/lib/python3.12/site-packages/coqpit/coqpit.py\"\n",
        "\n",
        "if not os.path.exists(target_file):\n",
        "    try:\n",
        "        found = subprocess.check_output(f\"find {venv_dir} -name coqpit.py\", shell=True, text=True).strip()\n",
        "        if found: target_file = found\n",
        "    except: pass\n",
        "\n",
        "if os.path.exists(target_file):\n",
        "    with open(target_file, \"r\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    patched = False\n",
        "\n",
        "    if \"if issubclass(field_type, Serializable):\" in content:\n",
        "        content = content.replace(\n",
        "            \"if issubclass(field_type, Serializable):\",\n",
        "            \"if isinstance(field_type, type) and issubclass(field_type, Serializable):\"\n",
        "        )\n",
        "        patched = True\n",
        "\n",
        "    if 'raise ValueError(f\" [!] \\'{type(x)}\\' value type' in content:\n",
        "         content = content.replace('raise ValueError(f\" [!] \\'{type(x)}\\' value type', 'pass # SUPPRESSED')\n",
        "         patched = True\n",
        "\n",
        "    if patched:\n",
        "        with open(target_file, \"w\") as f:\n",
        "            f.write(content)\n",
        "        print(\"   -> Patch is complete.\")\n",
        "else:\n",
        "    print(\"   -> File coqpit.py is not excist\")\n",
        "\n",
        "elapsed = int(time.time() - start_time)\n",
        "print(f\"\\nComplete! {elapsed} sec.\")\n",
        "print(\"Restart...\")\n",
        "\n",
        "time.sleep(3)\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Settings**\n",
        "\n",
        "### **Secret keys:**\n",
        "\n",
        "1. Look at the left sidebar of Google Colab and click on the ðŸ”‘ (Key icon) named ***\"Secrets\"***.\n",
        "\n",
        "2. **Telegram Token:** Go to Telegram, message `@BotFather`, use the `/newbot` command, and copy your **HTTP API Token**. Create a new secret in Colab named exactly `BOT_API` and paste your token as the value.\n",
        "\n",
        "3. **Groq API Key:** Go to `console.groq.com`, sign in, and generate a new API key. Create a second secret in Colab named exactly `GROQ_API` and paste the key.\n",
        "\n",
        "4. **Crucial Step:** Toggle the ***\"Notebook access\"*** switch to ON for both secrets!\n",
        "\n",
        "### **Basic Settings:**\n",
        "\n",
        "1. **BOT_NAME & LANGUAGE:** Choose a name for your AI and select the primary language for voice generation.\n",
        "\n",
        "2. **Model Paths:** Ensure these match the exact folder paths on your Google Drive where the LLM(text) and TTS(voice) models are stored.\n",
        "\n",
        "### **Advanced Settings (LLM & TTS):**\n",
        "\n",
        "1. **Temperature:** Controls creativity. Lower values make the AI logical and strict; higher values make it more creative and unpredictable.\n",
        "\n",
        "2. **Max Tokens:** Limits the maximum length of the bot's text responses.\n",
        "\n",
        "3. **Repetition Penalty & Top K/P:** Advanced parameters that prevent the AI from looping or repeating words, controlling its vocabulary richness. If unsure, leave them at their default values!\n",
        "\n",
        "**Action:** After setting up your secrets and sliders, run all cells in this section to save your configurations.\n"
      ],
      "metadata": {
        "id": "GQ2WuxuGRVJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Base**\n",
        "\n",
        "# Settings\n",
        "# @markdown ### **Bot**\n",
        "BOT_NAME = \"AI Companion\" # @param {type:\"string\"}\n",
        "LANGUAGE = \"ru\" # @param [\"en\", \"ru\", \"es\", \"fr\", \"de\", \"ja\"]\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ### **API**\n",
        "SECRET_BOT_API = \"BOT_API\" # @param {type:\"string\"}\n",
        "SECRET_GROQ_API = \"GROQ_API\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ### **Model Path**\n",
        "LLM_MODEL_PATH = \"/content/drive/My Drive/LLM_Model\" # @param {type:\"string\"}\n",
        "TTS_MODEL_PATH = \"/content/drive/My Drive/TTS_Model\" # @param {type:\"string\"}\n",
        "\n",
        "print(\"Settings confirmed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GOtYPIxIFec4",
        "outputId": "d9c81dad-0642-4611-f936-3a4a7462fe83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings confirmed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### **Advanced**\n",
        "\n",
        "# @markdown ### **LLM**\n",
        "LLM_TEMPERATURE = 0.6 # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "MAX_TOKENS = 128 # @param {type:\"slider\", min:64, max:1024, step:64}\n",
        "LLM_REPETITION_PENALTY = 1.1 # @param {type:\"slider\", min:1.0, max:2.0, step:0.05}\n",
        "LLM_TOP_K = 50 # @param {type:\"slider\", min:10, max:100, step:5}\n",
        "LLM_TOP_P = 0.95 # @param {type:\"slider\", min:0.5, max:1.0, step:0.05}\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ### **TTS**\n",
        "TTS_TEMPERATURE = 0.65 # @param {type:\"slider\", min:0.1, max:1.0, step:0.05}\n",
        "TTS_REPETITION_PENALTY = 2 # @param {type:\"slider\", min:1.0, max:2.0, step:0.05}\n",
        "TTS_TOP_K = 40 # @param {type:\"slider\", min:10, max:100, step:5}\n",
        "TTS_TOP_P = 0.8 # @param {type:\"slider\", min:0.5, max:1.0, step:0.05}\n",
        "\n",
        "print(\"Advanced Settings confirmed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "UJQ-r07InUJF",
        "outputId": "737574fe-3e3e-4b37-e6b0-1248ed81cb40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Advanced Settings confirmed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Load models**\n",
        "\n",
        "#### **!! If you have changed the settings, then restart this block !!**\n",
        "\n",
        "Press **Run and wait**. Do not proceed until you see the `Complete!` message at the bottom. It usually takes a few minutes."
      ],
      "metadata": {
        "id": "iXe-Va5MTb69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "3765bf8909ae40a3b7a122935bcd83c1",
            "68ba09381d7d4f31afeed753878bf44f",
            "50f9b7644e1b447597461c0bc3be0f12",
            "bd2a84f624af489f8ae740c7f5a61ce8",
            "4e7015b3bce841649bcfbd1d1ba0ad38",
            "63fb323f7d6c4437a024d711212c6031",
            "6e567f14cdcc4ffe8b9730924e8bd1ef",
            "d76a9cf7bf6d485682898bcaecfd66c9",
            "59236d04dea74c49b80c342e7ff61a2d",
            "343b52b070f44b3993b5ecc3b0c3ec91",
            "bdc9f22a6a0f45db96565c65a63b1b67",
            "233ec8c29217419aa71488f24f763258",
            "0ef9f61b6b724115a165a693fb348960",
            "6394c5c8dddb455c8781a41f082b67de",
            "9a4dd9ae63eb46f495db8d462b8adc21",
            "e5edc39d0bfd4c3c8d200100adaa383a",
            "65a4853d0faf4d4d88e383025e172576",
            "fd533c338d91463080794783fac409e8",
            "bf77730304ff48ca9ac7bcc516f62075",
            "5ba976d015854e779f41f84d3b75ca89",
            "7cfed5f2aa73428697e5002a3c331103",
            "6ef9a29ae163475faaebd0aa4f5b04f6"
          ]
        },
        "id": "pV5wdTOkID7F",
        "outputId": "bf27256b-9838-4804-87fc-9f3c60a8a3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cleaning up old background processes...\n",
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2026.2.1: Fast Llama patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3765bf8909ae40a3b7a122935bcd83c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "233ec8c29217419aa71488f24f763258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.2.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Complete! 293 sec.\n"
          ]
        }
      ],
      "source": [
        "# @title ### **Load**\n",
        "\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Cleaning up old background processes...\")\n",
        "os.system(\"pkill -f tts_runner.py\")\n",
        "os.system(\"fuser -k 5050/tcp\")\n",
        "time.sleep(2)\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 4096\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = LLM_MODEL_PATH,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "runner_code = \"\"\"\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "import traceback\n",
        "import json\n",
        "import subprocess\n",
        "import torch\n",
        "import torchaudio\n",
        "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "torch.set_num_threads(4)\n",
        "\n",
        "MODEL_PATH = \"[[TTS_MODEL_PATH]]\"\n",
        "REF_AUDIO = f\"{MODEL_PATH}/reference.wav\"\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(f\"{MODEL_PATH}/config.json\")\n",
        "tts_model = Xtts.init_from_config(config)\n",
        "tts_model.load_checkpoint(config, checkpoint_dir=MODEL_PATH, use_deepspeed=False)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    tts_model.cuda()\n",
        "\n",
        "class TTSHandler(BaseHTTPRequestHandler):\n",
        "    def do_POST(self):\n",
        "        try:\n",
        "            content_length = int(self.headers['Content-Length'])\n",
        "            data = json.loads(self.rfile.read(content_length))\n",
        "\n",
        "            text = data.get('text', '').replace('\\\\n', ' ').replace('\\\\r', ' ').strip()\n",
        "            if not text:\n",
        "                text = \"Empty text\"\n",
        "\n",
        "            output_file = data.get('output_file', 'response.ogg')\n",
        "\n",
        "            out = tts_model.synthesize(\n",
        "                text, config, speaker_wav=REF_AUDIO, gpt_cond_len=3,\n",
        "                language=\"[[LANGUAGE]]\",\n",
        "                temperature=float([[TTS_TEMPERATURE]]),\n",
        "                repetition_penalty=float([[TTS_REPETITION_PENALTY]]),\n",
        "                top_k=int([[TTS_TOP_K]]),\n",
        "                top_p=float([[TTS_TOP_P]])\n",
        "            )\n",
        "\n",
        "            temp_wav = \"temp_raw.wav\"\n",
        "            torchaudio.save(temp_wav, torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "\n",
        "            subprocess.run([\n",
        "                \"ffmpeg\", \"-y\", \"-i\", temp_wav,\n",
        "                \"-c:a\", \"libopus\", \"-b:a\", \"32k\", \"-vbr\", \"on\", output_file\n",
        "            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "            if os.path.exists(temp_wav):\n",
        "                os.remove(temp_wav)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            self.send_response(200)\n",
        "            self.send_header('Content-type', 'application/json')\n",
        "            self.end_headers()\n",
        "            self.wfile.write(json.dumps({\"status\": \"success\", \"file\": output_file}).encode('utf-8'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\\\n[x] Error generation:\")\n",
        "            traceback.print_exc()\n",
        "            self.send_response(500)\n",
        "            self.end_headers()\n",
        "\n",
        "    def log_message(self, format, *args):\n",
        "        pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    server = HTTPServer(('127.0.0.1', 5050), TTSHandler)\n",
        "    server.serve_forever()\n",
        "\"\"\"\n",
        "\n",
        "runner_code = runner_code.replace(\"[[TTS_MODEL_PATH]]\", TTS_MODEL_PATH)\n",
        "runner_code = runner_code.replace(\"[[LANGUAGE]]\", LANGUAGE)\n",
        "runner_code = runner_code.replace(\"[[TTS_TEMPERATURE]]\", str(TTS_TEMPERATURE))\n",
        "runner_code = runner_code.replace(\"[[TTS_REPETITION_PENALTY]]\", str(TTS_REPETITION_PENALTY))\n",
        "runner_code = runner_code.replace(\"[[TTS_TOP_K]]\", str(TTS_TOP_K))\n",
        "runner_code = runner_code.replace(\"[[TTS_TOP_P]]\", str(TTS_TOP_P))\n",
        "\n",
        "with open(\"tts_runner.py\", \"w\") as f:\n",
        "    f.write(runner_code)\n",
        "\n",
        "my_env = os.environ.copy()\n",
        "my_env[\"MPLBACKEND\"] = \"Agg\"\n",
        "\n",
        "subprocess.Popen(\n",
        "    \"nohup /content/tts_venv/bin/python -u tts_runner.py > tts_server.log 2>&1 &\",\n",
        "    shell=True,\n",
        "    env=my_env,\n",
        "    preexec_fn=os.setpgrp\n",
        ")\n",
        "time.sleep(12)\n",
        "\n",
        "elapsed = int(time.time() - start_time)\n",
        "print(f\"\\nComplete! {elapsed} sec.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Start telegram bot**\n",
        "**The final step!** This block contains the main logic and keeps your bot online.\n",
        "\n",
        "**Action:** Run this cell. Once you see the `Bot is running!` message in the console, open Telegram, find your bot, and send the `/start command`.\n",
        "\n",
        "**Important:** Keep this cell running and the browser tab open while you are chatting with your AI. If the execution stops, the bot will go offline."
      ],
      "metadata": {
        "id": "5xLekwJCTIqZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW5yKDzDIHVa",
        "outputId": "d9160cef-0e75-4e74-8f46-3300bd955f1c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot is running!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# @title ### **Start**\n",
        "\n",
        "from google.colab import userdata\n",
        "import asyncio, os, re, subprocess, base64, requests\n",
        "from aiogram import Bot, Dispatcher, types, F\n",
        "from aiogram.types import BotCommand, BotCommandScopeDefault, FSInputFile\n",
        "from aiogram.utils.chat_action import ChatActionSender\n",
        "from aiogram.filters import Command\n",
        "from groq import Groq\n",
        "from PIL import Image\n",
        "from collections import deque\n",
        "from moviepy.editor import VideoFileClip\n",
        "from lottie.parsers.tgs import parse_tgs\n",
        "from lottie.exporters.gif import export_gif\n",
        "\n",
        "# Initialize clients (Make sure keys are stored in Colab Secrets)\n",
        "groq_client = Groq(api_key=userdata.get(SECRET_GROQ_API))\n",
        "bot = Bot(token=userdata.get(SECRET_BOT_API))\n",
        "dp = Dispatcher()\n",
        "\n",
        "MAX_HISTORY_TOKENS = 2000\n",
        "\n",
        "# Globals\n",
        "user_histories = {}\n",
        "voice_mode = False\n",
        "\n",
        "# Variables for function reset\n",
        "last_message_obj = None\n",
        "last_user_text = \"\"\n",
        "last_system_instruction = \"\"\n",
        "last_user_id = None\n",
        "\n",
        "# Voice TTS Engine\n",
        "class VoiceEngine:\n",
        "    def __init__(self):\n",
        "        self.api_url = \"http://127.0.0.1:5050\"\n",
        "\n",
        "    def text_to_audio(self, text, output_filename=\"response.ogg\"):\n",
        "        try:\n",
        "            payload = {\"text\": text, \"output_file\": output_filename}\n",
        "            # Send text\n",
        "            response = requests.post(self.api_url, json=payload)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return output_filename\n",
        "            else:\n",
        "                print(\"Error: TTS Server returned a non-200 status.\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error connecting to TTS Server: {e}\")\n",
        "            return None\n",
        "\n",
        "voice_engine = VoiceEngine()\n",
        "\n",
        "# Vision (Groq API)\n",
        "def describe_image(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "        image_url = f\"data:image/jpeg;base64,{encoded_string}\"\n",
        "\n",
        "        chat_completion = groq_client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Describe in detail what is in this picture.\"},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama-3.2-11b-vision-preview\",\n",
        "        )\n",
        "        return chat_completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Vision Error: {e}\"\n",
        "\n",
        "# Transcribe (Whisper API)\n",
        "def transcribe_audio(audio_path):\n",
        "    try:\n",
        "        with open(audio_path, \"rb\") as file:\n",
        "            transcription = groq_client.audio.transcriptions.create(\n",
        "                file=(audio_path, file.read()),\n",
        "                model=\"whisper-large-v3-turbo\",\n",
        "                language=LANGUAGE,\n",
        "                response_format=\"json\",\n",
        "                temperature=0.0\n",
        "            )\n",
        "        return transcription.text\n",
        "    except Exception as e:\n",
        "        return f\"Audio Error: {e}\"\n",
        "\n",
        "# Generate text message\n",
        "def generate_message(message, instruction):\n",
        "    input_text = alpaca_prompt.format(\n",
        "        message,\n",
        "        instruction,\n",
        "        \"\",\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens = MAX_TOKENS,\n",
        "        use_cache = True,\n",
        "        temperature = LLM_TEMPERATURE,\n",
        "        repetition_penalty = LLM_REPETITION_PENALTY,\n",
        "        top_k = LLM_TOP_K,\n",
        "        top_p = LLM_TOP_P,\n",
        "        tokenizer = tokenizer,\n",
        "        stop_strings = [\"\\n###\", \"###\", \"[System\", \"User:\"],\n",
        "    )\n",
        "\n",
        "    response = tokenizer.batch_decode(outputs)[0]\n",
        "    clean_text = re.sub(r'<think>.*?</think>', '', response.split(\"### Response:\\n\")[-1].split(\"###\")[0].strip().split(\"<ï½œendâ–ofâ–sentenceï½œ>\")[0], flags=re.DOTALL).strip()\n",
        "    return clean_text\n",
        "\n",
        "# Format converters for media\n",
        "def convert_webp_to_jpg(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "        rgb_im = img.convert(\"RGB\")\n",
        "        rgb_im.save(output_path, \"JPEG\", quality=95)\n",
        "\n",
        "def convert_webm_to_jpg(input_path, output_path):\n",
        "    clip = VideoFileClip(input_path)\n",
        "    clip.save_frame(output_path, t=0)\n",
        "    clip.close()\n",
        "\n",
        "def convert_tgs_to_jpg(input_path, output_path):\n",
        "    temp_gif = \"temp_sticker.gif\"\n",
        "    animation = parse_tgs(input_path)\n",
        "    export_gif(animation, temp_gif)\n",
        "\n",
        "    try:\n",
        "        with Image.open(temp_gif) as img:\n",
        "            img.seek(0)\n",
        "            background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
        "            img_rgba = img.convert(\"RGBA\")\n",
        "            background.paste(img_rgba, mask=img_rgba.split()[3])\n",
        "            background.save(output_path, \"JPEG\", quality=95)\n",
        "    finally:\n",
        "        if os.path.exists(temp_gif):\n",
        "            os.remove(temp_gif)\n",
        "\n",
        "\n",
        "# Safe History\n",
        "def get_safe_history(user_id, new_text=\"\"):\n",
        "    if user_id not in user_histories:\n",
        "        user_histories[user_id] = deque(maxlen=50)\n",
        "        return \"\"\n",
        "\n",
        "    while True:\n",
        "        history_text = \"\".join([f\"{role}: {text}\\n\" for role, text in user_histories[user_id]])\n",
        "        test_prompt = f\"{history_text}\\nUser: {new_text}\"\n",
        "\n",
        "        try:\n",
        "            tokens = tokenizer.encode(test_prompt)\n",
        "            token_count = len(tokens)\n",
        "        except Exception:\n",
        "            token_count = 0\n",
        "\n",
        "        if token_count <= MAX_HISTORY_TOKENS or len(user_histories[user_id]) == 0:\n",
        "            break\n",
        "\n",
        "        user_histories[user_id].popleft()\n",
        "\n",
        "    return history_text\n",
        "\n",
        "\n",
        "# Unified message sender (Handles Text or Voice)\n",
        "async def new_message_text_or_voice(message, temp_message, response_text, user_text, system_instruction):\n",
        "    global voice_mode, last_system_instruction, last_user_text, last_message_obj\n",
        "\n",
        "    if voice_mode:\n",
        "        audio_path = await asyncio.to_thread(voice_engine.text_to_audio, response_text)\n",
        "        if audio_path and os.path.exists(audio_path):\n",
        "            try:\n",
        "                voice_file = FSInputFile(audio_path)\n",
        "                await temp_message.delete()\n",
        "                last_message_obj = await message.answer_voice(voice_file)\n",
        "                os.remove(audio_path)\n",
        "            except Exception as e:\n",
        "                await temp_message.delete()\n",
        "                last_message_obj = await message.answer(f\"{response_text}\\n(Voice send error: {e})\")\n",
        "        else:\n",
        "            await temp_message.delete()\n",
        "            last_message_obj = await message.answer(f\"{response_text}\\n(Voice generation failed)\")\n",
        "    else:\n",
        "        await temp_message.delete()\n",
        "        last_message_obj = await message.answer(text=response_text)\n",
        "\n",
        "    last_system_instruction = system_instruction\n",
        "    last_user_text = user_text\n",
        "\n",
        "# Command: /start\n",
        "@dp.message(Command(\"start\"))\n",
        "async def start_command(message: types.Message):\n",
        "    await message.answer(text=f\"Hello! I am {BOT_NAME}. How can I help you today?\")\n",
        "    try: await message.delete()\n",
        "    except: pass\n",
        "\n",
        "# Command: /reset_memory\n",
        "@dp.message(Command(\"reset_memory\"))\n",
        "async def memory_reset(message: types.Message):\n",
        "    user_id = message.from_user.id\n",
        "    if user_id in user_histories:\n",
        "        user_histories[user_id].clear()\n",
        "    await message.answer(\"Memory cleared! Let's start a new conversation.\")\n",
        "\n",
        "# Command: /reset (Regenerates last message)\n",
        "@dp.message(Command(\"reset\"))\n",
        "async def reset_last_message(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id\n",
        "\n",
        "    if last_message_obj is None:\n",
        "        await message.answer(\"There is no previous message to reset.\")\n",
        "        return\n",
        "\n",
        "    await last_message_obj.delete()\n",
        "\n",
        "    status_text = \"Generating voice...\" if voice_mode else \"Typing...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    try: await message.delete()\n",
        "    except: pass\n",
        "\n",
        "    history_text = get_safe_history(last_user_id, last_user_text)\n",
        "\n",
        "    try:\n",
        "        new_response_text = await asyncio.to_thread(generate_message, last_user_text, last_system_instruction)\n",
        "    except Exception as e:\n",
        "        new_response_text = f\"Error: {e}\"\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, new_response_text, last_user_text, last_system_instruction)\n",
        "\n",
        "    if last_user_id in user_histories and len(user_histories[last_user_id]) > 0:\n",
        "        user_histories[last_user_id].pop()\n",
        "        user_histories[last_user_id].append((\"AI\", new_response_text))\n",
        "\n",
        "# Command: /voice_mode\n",
        "@dp.message(Command(\"voice_mode\"))\n",
        "async def turn_voice_mode(message: types.Message):\n",
        "    global voice_mode\n",
        "    voice_mode = not voice_mode\n",
        "\n",
        "    if voice_mode:\n",
        "        await message.answer(text=\"Voice mode enabled. I will now reply with audio messages.\")\n",
        "    else:\n",
        "        await message.answer(text=\"Voice mode disabled. I will reply with text.\")\n",
        "\n",
        "# Handler: Photo\n",
        "@dp.message(F.photo)\n",
        "async def reply_bot_user_send_photo(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id\n",
        "\n",
        "    status_text = \"Thinking (Voice)...\" if voice_mode else \"Thinking...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    last_user_id = user_id\n",
        "\n",
        "    if user_id not in user_histories:\n",
        "        user_histories[user_id] = deque(maxlen=10)\n",
        "\n",
        "    output_file = f\"{user_id}.jpg\"\n",
        "    await bot.download(message.photo[-1], destination=output_file)\n",
        "\n",
        "    try:\n",
        "        description = describe_image(output_file)\n",
        "    except Exception as e:\n",
        "        description = None\n",
        "        response_text = f\"Error: {e}\"\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"[Context: The user sent a photo. You are {BOT_NAME}. \"\n",
        "        \"Your task: React to this photo naturally.]\"\n",
        "    )\n",
        "    user_text_simulation = f\"(Photo description: {description})\"\n",
        "\n",
        "    history_text = get_safe_history(user_id, user_text_simulation)\n",
        "\n",
        "    if description:\n",
        "        try:\n",
        "            response_text = await asyncio.to_thread(generate_message, user_text_simulation, system_instruction)\n",
        "        except Exception as e:\n",
        "            response_text = f\"Error: {e}\"\n",
        "\n",
        "    user_histories[user_id].append((\"User\", user_text_simulation))\n",
        "    user_histories[user_id].append((\"AI\", response_text))\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, response_text, user_text_simulation, system_instruction)\n",
        "\n",
        "    if os.path.exists(output_file):\n",
        "        os.remove(output_file)\n",
        "\n",
        "# Handler: Sticker\n",
        "@dp.message(F.sticker)\n",
        "async def reply_bot_user_send_sticker(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id\n",
        "\n",
        "    sticker = message.sticker\n",
        "    status_text = \"Thinking (Voice)...\" if voice_mode else \"Thinking...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    last_user_id = user_id\n",
        "\n",
        "    if user_id not in user_histories:\n",
        "        user_histories[user_id] = deque(maxlen=10)\n",
        "\n",
        "    file = await bot.get_file(message.sticker.file_id)\n",
        "    file_path = file.file_path.split(\"/\")[-1]\n",
        "\n",
        "    await bot.download(file, destination=file_path)\n",
        "    output_filename = f\"{file_path}.jpg\"\n",
        "\n",
        "    if sticker.is_video:\n",
        "        await asyncio.to_thread(convert_webm_to_jpg, file_path, output_filename)\n",
        "    elif sticker.is_animated:\n",
        "        await asyncio.to_thread(convert_tgs_to_jpg, file_path, output_filename)\n",
        "    else:\n",
        "        convert_webp_to_jpg(file_path, output_filename)\n",
        "\n",
        "    try:\n",
        "        description = describe_image(output_filename)\n",
        "    except Exception as e:\n",
        "        description = None\n",
        "        response_text = f\"Error: {e}\"\n",
        "\n",
        "    if os.path.exists(file_path): os.remove(file_path)\n",
        "    if os.path.exists(output_filename): os.remove(output_filename)\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"[Context: The user sent a sticker. You are {BOT_NAME}. \"\n",
        "        \"Your task: React to this sticker naturally.]\"\n",
        "    )\n",
        "    user_text_simulation = f\"(Sticker description: {description})\"\n",
        "\n",
        "    history_text = get_safe_history(user_id, user_text_simulation)\n",
        "\n",
        "    if description:\n",
        "        try:\n",
        "            response_text = await asyncio.to_thread(generate_message, user_text_simulation, system_instruction)\n",
        "        except Exception as e:\n",
        "            response_text = f\"Error: {e}\"\n",
        "\n",
        "    user_histories[user_id].append((\"User\", user_text_simulation))\n",
        "    user_histories[user_id].append((\"AI\", response_text))\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, response_text, user_text_simulation, system_instruction)\n",
        "\n",
        "# Handler: Animation (GIF)\n",
        "@dp.message(F.animation)\n",
        "async def handle_gif(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id\n",
        "\n",
        "    status_text = \"Thinking (Voice)...\" if voice_mode else \"Thinking...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    last_user_id = user_id\n",
        "\n",
        "    if user_id not in user_histories:\n",
        "        user_histories[user_id] = deque(maxlen=10)\n",
        "\n",
        "    file = await bot.get_file(message.animation.file_id)\n",
        "    file_path = f\"{user_id}_{file.file_id}.mp4\"\n",
        "\n",
        "    await bot.download(file, destination=file_path)\n",
        "    output_filename = f\"{file_path}.jpg\"\n",
        "\n",
        "    await asyncio.to_thread(convert_webm_to_jpg, file_path, output_filename)\n",
        "\n",
        "    try:\n",
        "        description = describe_image(output_filename)\n",
        "    except Exception as e:\n",
        "        description = None\n",
        "        response_text = f\"Error: {e}\"\n",
        "\n",
        "    if os.path.exists(file_path): os.remove(file_path)\n",
        "    if os.path.exists(output_filename): os.remove(output_filename)\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"[Context: The user sent a GIF. You are {BOT_NAME}. \"\n",
        "        \"Your task: React to this GIF naturally.]\"\n",
        "    )\n",
        "    user_text_simulation = f\"(GIF description: {description})\"\n",
        "\n",
        "    history_text = get_safe_history(user_id, user_text_simulation)\n",
        "\n",
        "    if description:\n",
        "        try:\n",
        "            response_text = await asyncio.to_thread(generate_message, user_text_simulation, system_instruction)\n",
        "        except Exception as e:\n",
        "            response_text = f\"Error: {e}\"\n",
        "\n",
        "    user_histories[user_id].append((\"User\", user_text_simulation))\n",
        "    user_histories[user_id].append((\"AI\", response_text))\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, response_text, user_text_simulation, system_instruction)\n",
        "\n",
        "# Handler: Voice\n",
        "@dp.message(F.voice)\n",
        "async def reply_bot_user_send_voice(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id, voice_mode\n",
        "\n",
        "    status_text = \"Listening...\" if voice_mode else \"Typing...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    last_user_id = user_id\n",
        "\n",
        "    file = await bot.get_file(message.voice.file_id)\n",
        "    file_path = f\"{user_id}_{file.file_id}.ogg\"\n",
        "    await bot.download(file=file, destination=file_path)\n",
        "\n",
        "    try:\n",
        "        transcribe_text = transcribe_audio(file_path)\n",
        "    except Exception as e:\n",
        "        transcribe_text = None\n",
        "        response_text = f\"Error: {e}\"\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "    history_text = get_safe_history(user_id, transcribe_text)\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"You are {BOT_NAME}. Your task is to answer the user's questions in a friendly manner. \"\n",
        "        f\"Here is the chat history:\\n{history_text}\\n\"\n",
        "        f\"The user just said: {transcribe_text}\"\n",
        "    )\n",
        "\n",
        "    if transcribe_text:\n",
        "        try:\n",
        "            response_text = await asyncio.to_thread(generate_message, transcribe_text, system_instruction)\n",
        "        except Exception as e:\n",
        "            response_text = f\"Error: {e}\"\n",
        "\n",
        "    user_histories[user_id].append((\"User\", transcribe_text))\n",
        "    user_histories[user_id].append((\"AI\", response_text))\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, response_text, transcribe_text, system_instruction)\n",
        "\n",
        "# Handler: Text\n",
        "@dp.message(F.text)\n",
        "async def reply_bot_user_send_text(message: types.Message):\n",
        "    global last_message_obj, last_user_text, last_system_instruction, last_user_id, voice_mode\n",
        "\n",
        "    status_text = \"Generating voice...\" if voice_mode else \"Typing...\"\n",
        "    temp_message = await message.answer(text=status_text)\n",
        "\n",
        "    user_id = message.from_user.id\n",
        "    last_user_id = user_id\n",
        "\n",
        "    history_text = get_safe_history(user_id, message.text)\n",
        "\n",
        "    system_instruction = (\n",
        "        f\"You are {BOT_NAME}. Your task is to answer the user's questions in a friendly manner. \"\n",
        "        f\"Here is the chat history:\\n{history_text}\\n\"\n",
        "        f\"The user just wrote: {message.text}\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response_text = await asyncio.to_thread(generate_message, message.text, system_instruction)\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error: {e}\"\n",
        "\n",
        "    user_histories[user_id].append((\"User\", message.text))\n",
        "    user_histories[user_id].append((\"AI\", response_text))\n",
        "\n",
        "    await new_message_text_or_voice(message, temp_message, response_text, message.text, system_instruction)\n",
        "\n",
        "\n",
        "async def main():\n",
        "    print(\"Bot is running!\")\n",
        "\n",
        "    commands = [\n",
        "        BotCommand(command=\"start\", description=\"Start chatting with the bot\"),\n",
        "        BotCommand(command=\"reset\", description=\"Regenerate the last message\"),\n",
        "        BotCommand(command=\"reset_memory\", description=\"Clear chat history and context\"),\n",
        "        BotCommand(command=\"voice_mode\", description=\"Toggle text-to-speech voice replies\")\n",
        "    ]\n",
        "\n",
        "    await bot.set_my_commands(commands, scope=BotCommandScopeDefault())\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "try:\n",
        "    await main()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Bot stopped.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3765bf8909ae40a3b7a122935bcd83c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68ba09381d7d4f31afeed753878bf44f",
              "IPY_MODEL_50f9b7644e1b447597461c0bc3be0f12",
              "IPY_MODEL_bd2a84f624af489f8ae740c7f5a61ce8"
            ],
            "layout": "IPY_MODEL_4e7015b3bce841649bcfbd1d1ba0ad38"
          }
        },
        "68ba09381d7d4f31afeed753878bf44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fb323f7d6c4437a024d711212c6031",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e567f14cdcc4ffe8b9730924e8bd1ef",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "50f9b7644e1b447597461c0bc3be0f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76a9cf7bf6d485682898bcaecfd66c9",
            "max": 5964186418,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59236d04dea74c49b80c342e7ff61a2d",
            "value": 5964186418
          }
        },
        "bd2a84f624af489f8ae740c7f5a61ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343b52b070f44b3993b5ecc3b0c3ec91",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bdc9f22a6a0f45db96565c65a63b1b67",
            "value": "â€‡5.96G/5.96Gâ€‡[02:35&lt;00:00,â€‡28.6MB/s]"
          }
        },
        "4e7015b3bce841649bcfbd1d1ba0ad38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fb323f7d6c4437a024d711212c6031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e567f14cdcc4ffe8b9730924e8bd1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76a9cf7bf6d485682898bcaecfd66c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59236d04dea74c49b80c342e7ff61a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "343b52b070f44b3993b5ecc3b0c3ec91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc9f22a6a0f45db96565c65a63b1b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233ec8c29217419aa71488f24f763258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ef9f61b6b724115a165a693fb348960",
              "IPY_MODEL_6394c5c8dddb455c8781a41f082b67de",
              "IPY_MODEL_9a4dd9ae63eb46f495db8d462b8adc21"
            ],
            "layout": "IPY_MODEL_e5edc39d0bfd4c3c8d200100adaa383a"
          }
        },
        "0ef9f61b6b724115a165a693fb348960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a4853d0faf4d4d88e383025e172576",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fd533c338d91463080794783fac409e8",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "6394c5c8dddb455c8781a41f082b67de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf77730304ff48ca9ac7bcc516f62075",
            "max": 236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ba976d015854e779f41f84d3b75ca89",
            "value": 236
          }
        },
        "9a4dd9ae63eb46f495db8d462b8adc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cfed5f2aa73428697e5002a3c331103",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6ef9a29ae163475faaebd0aa4f5b04f6",
            "value": "â€‡236/236â€‡[00:00&lt;00:00,â€‡11.9kB/s]"
          }
        },
        "e5edc39d0bfd4c3c8d200100adaa383a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a4853d0faf4d4d88e383025e172576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd533c338d91463080794783fac409e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf77730304ff48ca9ac7bcc516f62075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba976d015854e779f41f84d3b75ca89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cfed5f2aa73428697e5002a3c331103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef9a29ae163475faaebd0aa4f5b04f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}